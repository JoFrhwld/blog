{
  "hash": "8f86ec678b87706d1beda5344b6dbf23",
  "result": {
    "markdown": "---\ntitle: \"What *is* R?\"\nauthor: \"Josef Fruehwald\"\ndate: 2022-12-17\neditor: visual\nimage: \"2022-12-17_files/figure-html/fig-network-1.png\"\ntwitter-card:\n  image: \"2022-12-17_files/figure-html/fig-network-1.png\"\nopen-graph:\n  image: \"2022-12-17_files/figure-html/fig-network-1.png\"\ncode-fold: true\ncategories:\n  - \"R\"\ncitation:\n  url: \"https://jofrhwld.github.io/blog/posts/2022/12/2022-12-17.html\"\n---\n\n\nIn the Spring 2023 semester, I'm going to be teaching two R intensive courses: a statistics for linguists course, and an R for the Arts and Sciences course. For both, I'm going to have to do a \"What is R\" discussion during week 1, and given the breadth of tools I hope students come away with, I've been rethinking my usual answers.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Loading Libraries\"}\nlibrary(tidyverse)\nlibrary(crandep)\nlibrary(igraph)\nlibrary(ggnetwork)\nlibrary(ggrepel)\nlibrary(patchwork)\nlibrary(plotly)\nlibrary(khroma)\nlibrary(scales)\n```\n:::\n\n\n## A programming language?\n\nThe [Wikipedia slug for R](https://en.wikipedia.org/wiki/R_(programming_language)) says\n\n> **R** is a programming language for statistical computing and graphics supported by the R Core Team and the R Foundation for Statistical Computing\n\nAnd yeah, it is definitely a programming language. Here it is doing some programming language things:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n2+2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n2+2 < 5\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n\nAnd it can do statistical computing, like a linear model\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ncars_model <- lm(dist ~ speed, data = cars)\nsummary(cars_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = dist ~ speed, data = cars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.069  -9.525  -2.272   9.215  43.201 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -17.5791     6.7584  -2.601   0.0123 *  \nspeed         3.9324     0.4155   9.464 1.49e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.38 on 48 degrees of freedom\nMultiple R-squared:  0.6511,\tAdjusted R-squared:  0.6438 \nF-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12\n```\n:::\n:::\n\n\nAnd it can do graphics.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\n# `PLOT_FONT <- \"Fira Sans\"` in my .Rprofile\npar(family = PLOT_FONT)\nplot(cars)\n```\n\n::: {.cell-output-display}\n![A plot](2022-12-17_files/figure-html/fig-carsplot-1.png){#fig-carsplot fig-align='center' fig-alt='A base graphics scatter plot showing the relationship between speed and distance from the cars default data frame.' width=576}\n:::\n:::\n\n\nObviously, none of these things are *unique* to R. In the other programming language I know best, Python, you can [fit a linear model](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) and [make a scatter plot](https://matplotlib.org/stable/plot_types/basic/scatter_plot.html). What differentiates programming languages, in my experience, is what kinds of operations, data structures, and workflows it prioritizes.\n\nFor R, I think it's uncontroversial to say it prioritizes rectangular data with mixed data-type rows & single data-type columns and also provides a lot of options for indexing column-wise. And a lot of the extensions to R have leaned into this prioritization *hard*.\n\n## An ecosystem?\n\nBut \"R\" isn't just a programming language, it's also an ecosystem of community created packages. \"Learning R\" involves learning about these packages, and how they're interrelated. I grabbed the list of all packages on [CRAN](https://cran.r-project.org/) and the packages they import with the [`crandep`](https://github.com/clement-lee/crandep) package.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ncran_df <- crandep::get_dep_all_packages()\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Import Summaries\"}\ncran_df |> \n  filter(type == \"imports\", !reverse) |> \n  count(to) |> \n  arrange(desc(n)) |> \n  mutate(rank = 1:n()) -> imported\n\nimported_10 <- imported |> slice(1:10)\n```\n:::\n\n\nIf you count up how often each package gets imported and rank them, you get the familiar power-law plot. I've plotted this one out a bit non standard-ly so that frequency is on the x axis for both the main plot and the inset, and so that I could include the package names in the inset with horizontal text.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-summary=\"Plotting code\"}\nimported |> \n  ggplot(aes(n, rank))+\n    geom_point()+\n    scale_x_log10(labels = label_comma())+\n    scale_y_log10(labels = label_comma())+\n    labs(title = \"Frequency by rank of imported R packages\") -> mainplot\n\nimported_10 |> \n  mutate(to = as.factor(to),\n          to = fct_reorder(to, rank)) |> \n  ggplot(aes(n, to))+\n    geom_col(fill = \"white\")+\n    geom_text(aes(label = to,\n                  x = 0), \n              color = \"grey10\",\n              hjust = 0,\n              nudge_x = 100, \n              family = PLOT_FONT,\n              size = 4.5)+\n    scale_x_continuous(expand = expansion(mult = 0),\n                       labels = label_comma())+\n    theme(axis.text.y = element_blank(),\n          text = element_text(size = 10),\n          panel.grid.minor  = element_blank(),\n          panel.grid.major.y = element_blank())+\n    labs(y = NULL,\n         title = \"top10\") -> inset\n \nmainplot + inset_element(inset, 0.05, 0.05, 0.5, 0.6)\n```\n\n::: {.cell-output-display}\n![A log(rank) by log(frequency) plot of R imports](2022-12-17_files/figure-html/fig-rank-1.png){#fig-rank fig-align='center' fig-alt='The main figure shows the linear decreasing relationship between log(frequency) and log(rank). The inset is a bar graph showing the import frequency of the top 10 packages, which are stats, utils, methods, dplyr, ggplot2, Rcpp, graphics, magrittr, rlang, stringr' width=768}\n:::\n:::\n\n\nHere's a network visualization of these imports and dependencies. I color coded the nodes according to common R package naming trends\n\n-   `gg*` - Packages extending `ggplot2`\n\n-   `tidy*` - Packages declaring their adherence to [tidy-data principles](https://www.jstatsoft.org/article/view/v059i10) (and the tidyverse more generally)\n\n-   `*r` - Packages declaring that they are... R packages\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Network graph setup\"}\nimported |>\n  filter(n >= 5) |> \n  pull(to) -> to_network\n\ncran_df |>\n  filter(!reverse, type == \"imports\",\n         to %in% to_network) |>\n  df_to_graph(nodelist = cran_df |> rename(name = from)) -> cran_network\n\nset.seed(300)\ncran_flat <- ggnetwork(cran_network, layout = with_drl())\n\nxclip <- quantile(cran_flat$x, c(0.0025, 0.9975))\nyclip <- quantile(cran_flat$y, c(0.0025, 0.9975))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-summary=\"Network graph\"}\ncran_flat |> \n  mutate(name_pattern = case_when(str_detect(name, \"[rR]$\") ~ \"thingr\",\n                                  str_detect(name, \"tidy\") ~ \"tidy\",\n                                  str_detect(name, \"^[Gg]g\") ~ \"gg\",\n                                  T ~ \"else\"),\n         name_pattern = factor(name_pattern, levels = c(\"tidy\", \"gg\", \"thingr\", \"else\"))) |> \n  arrange(desc(name_pattern)) |> \n  filter(x >= xclip[1], x <= xclip[2],\n         y >= yclip[1], y <= yclip[2]) |> \nggplot(aes(x = x, y = y, xend = xend, yend = yend, color = name_pattern))+\n  #geom_nodes()+  \n  geom_nodes(aes(alpha = name_pattern))+\n  scale_color_bright(limits = c(\"tidy\", \"gg\", \"thingr\", \"else\"),\n                     labels = c(\"tidy*\", \"gg*\", \"*r\", \"else\"))+\n  dark_theme_void()+\n  scale_alpha_manual(values = c(0.5,0.3, 0.08, 0.02), \n                     limits = c(\"tidy\", \"gg\", \"thingr\", \"else\"),\n                     guide = \"none\")+\n  labs(color = NULL,\n       title = \"CRAN imports network visualization\")+\n  theme(legend.position = c(0.2,0.8), \n        legend.text = element_text(family = PLOT_FONT),\n        text = element_text(family = PLOT_FONT),\n        plot.title = element_text(hjust = 0.5))\n```\n\n::: {.cell-output-display}\n![CRAN network graph](2022-12-17_files/figure-html/fig-network-1.png){#fig-network fig-align='center' fig-alt='A network diagram displaying just the nodes, color coded according to their name pattern: beginning with tidy, beginning with gg, ending with r, and else' width=480}\n:::\n:::\n\n\n## A communications platform?\n\nBut beyond just the R packages that implement specific analysis or process data in a specific way, there are also all of the tools built *around* R (and mostly around the RStudio IDE) that also make R what I might call a \"communications platform.\" From [Sweave](https://en.wikipedia.org/wiki/Sweave) to [knitr](https://yihui.org/knitr/) to [rmarkdown](https://rmarkdown.rstudio.com/) and now [Quarto](https://quarto.org/), the kind of literate programming you can do in R has moved from ugly[^1] Beamer slides to, well, full on blogs.\n\n[^1]: sorry, but they are\n\nBut, it's not just for the novelty or nerd appeal that I think it's important to learn about R authoring tools available. They've also changed my own discovery and learning process about new packages. You can always find the documentation for a package on CRAN, but you should *really* try to find its [`pkgdown`](https://pkgdown.r-lib.org/) site.[^2]\n\n[^2]: Most often, click on the URL listed on CRAN, which takes you to the package's github, which *then* probably has a link to the `pkgdown` site in its \"about\" box.\n\n## What does it mean to \"know R\"?\n\nWhen I think about what it means to \"know R\", and my goal for the kind of knowledge my students should start getting a handle on, it involves all of these components: the programming syntax, the social graph of the ecosystem, and the authoring tools to use and seek out.\n\nA lot of other programming languages have similar kinds of features, especially Python with [pypi](https://pypi.org/) or [conda](https://docs.conda.io/en/latest/) keeping track of the ecosystem and [Sphinx](https://www.sphinx-doc.org/en/master/) providing the authoring tools. There too I'd say that getting to \"know Python\" involves a lot more than learning its syntax.\n",
    "supporting": [
      "2022-12-17_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}