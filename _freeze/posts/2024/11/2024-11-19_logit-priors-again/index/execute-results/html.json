{
  "hash": "1bf53eec1560d62447de9010359b38d6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Random effect priors, redo\ndate: 2024-11-19\nformat:\n  html:\n    fig-width: 5\n    fig-asp: 0.618\n    out-width: 70%\n    fig-align: center\n---\n\n::: {.cell}\n\n:::\n\n\n\n\nFor me, teaching stats this semester has turned into a journey of discovering what the `{distributional}` and `{ggdist}` packages can do for me. The way I make illustrative figures will never be the same. So I thought I'd revisit [my post about hierarchical variance priors](/posts/2023/06/2023-06-29_hierarchical-variance/), this time implementing the figures using these two packages.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tibble)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scico)\nlibrary(ggdist)\nlibrary(distributional)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Custom y theme and scale\"}\ntheme_no_y <- function(){\n\n  out_theme <- theme(\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.title.y = element_blank()\n  )\n\n  out_theme  \n}\n\nscale_y_tight <- function(...) {\n  scale_y_continuous(expand = expansion(0), ...)\n}\n```\n:::\n\n\n\n\n# Random effect variance priors\n\nWhen fitting a model with a random intercept, the group-level random effects (let's say, $\\gamma_i$) are sampled from a normal distribution\n\n$$\n\\gamma_i \\sim \\mathcal{N}(0,\\sigma)\n$$\n\nIf you look at the default prior brms uses for $\\sigma$, it's a truncated student-t:\n\n```         \nstudent_t(3, 0, 2.5)\n```\n\nWe can make this distribution!\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_t <- dist_student_t(\n  df = 3, \n  mu = 0, \n  sigma = 2.5\n)\n\nhalf_t <- dist_truncated(\n  full_t, \n  lower = 0\n)\n```\n:::\n\n\n\n\nWe can get things like the mean and variance of this truncated distribution, and generate random samples from it\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(half_t)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.756644\n```\n\n\n:::\n\n```{.r .cell-code}\nvariance(half_t)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 11.15091\n```\n\n\n:::\n\n```{.r .cell-code}\ngenerate(half_t, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n [1] 5.1531979 1.2497857 1.0370256 3.0964036 4.6862006 1.1580219 0.2008173\n [8] 8.3719751 2.6385236 0.2936411\n```\n\n\n:::\n:::\n\n\n\n\nAnd we can plot it\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot()+\n  stat_slab(\n    aes(\n      xdist = half_t\n    ),\n    fill = \"#EE6677\"\n  )+\n  scale_y_tight()+\n  theme_no_y()+\n  scale_thickness_shared() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=480}\n:::\n:::\n\n\n\n\nLet's just use the expected value of this distribution as $\\sigma$ for now.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninit_sigma <- mean(half_t)\n```\n:::\n\n\n\n\n# Random effects in probability space\n\nNow let's make the normal distribution for the group-level random effects.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nranef_dist <- dist_normal(\n  mu = 0, \n  sigma = init_sigma\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot()+\n  stat_slab(\n    aes(\n      xdist = ranef_dist\n    ),\n    fill = \"#EE6677\"\n  )+\n  scale_y_tight()+\n  theme_no_y()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=480}\n:::\n:::\n\n\n\n\nOk, great! But what if the model I'm fitting is a logistic regression? This random effects distribution is in the logit space. But what does it look like if we transform it to the probability space?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nranef_prob_dist <- dist_transformed(\n  ranef_dist,\n  plogis,\n  qlogis\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot()+\n  stat_slab(\n    aes(\n      xdist = ranef_prob_dist\n    ),\n    fill = \"#EE6677\"\n  )+\n  scale_y_tight()+\n  theme_no_y()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=480}\n:::\n:::\n\n\n\n\nRather than having a random effects distribution where groups are broadly distributed across the probability space, we actually have a random effects distribution where groups are pretty strongly bifurcated. And this is at the expected value for our prior over $\\sigma$.\n\n## Looking for a more neutral distribution\n\nLet's see what different $\\sigma$s look like in the probability space.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npossible_dists <- tibble(\n  sigma = seq(\n    1, 2.1, by = 0.1\n  ),\n  dist = dist_normal(0, sigma),\n  p_dist = dist_transformed(\n    dist, plogis, qlogis\n  )\n)\n\nggplot(\n  possible_dists,\n  aes(\n    xdist = p_dist,\n    fill = sigma\n  )\n)+\n  stat_slab(\n    color = \"black\",\n    linewidth = 0.5\n  )+\n  scale_fill_scico(\n    palette = \"devon\",\n    guide = \"none\"\n  )+\n  scale_y_tight()+\n  facet_wrap(~sigma)+\n  theme_no_y()+\n  theme_no_x()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n\nIt looks like somewhere between 1.3 and 1.4 is the sweet spot for a maximally flat random effects distribution in the probability space.\n\n## Really honing in on it\n\nI can try getting even more precise by looking at a vectorized version of these distributions, and finding the largest sigma what still has its density peak at 0.5.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(purrr)\n\n# a vector of sigmas\nsigmas = seq(1.3, 1.5, length = 100)\n\n# a vectorized normal\nvec_dist <- dist_normal(\n  mu = 0,\n  sigma = sigmas\n) \n\n# a vectorized ilogit(normal)\nvec_p_dist <- dist_transformed(\n  vec_dist,\n  plogis,\n  qlogis\n)\n\n# the density function\n# from 0 to 0.5\np_densities <- density(\n  vec_p_dist, \n  seq(0, 0.5, length = 100)\n)\n\n# The index of the max\n# density\nwhere_is_max <- p_densities |> \n  map_vec(\n    which.max\n  ) \n\n# if where_is_max == 100\n# peak density was at 0.5\nflat_idx <- (where_is_max == 100) |> \n  which() |> \n  max()\n\nflattest_sigma <- sigmas[flat_idx]\n\nflattest_sigma\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.413131\n```\n\n\n:::\n:::\n\n\n\n\nLet's take a look at it:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflat_pdist <- dist_normal(0, flattest_sigma) |> \n  dist_transformed(plogis,qlogis)\n  \nggplot()+\n  stat_slab(\n    aes(\n      xdist = flat_pdist\n    ),\n    fill = \"#EE6677\"\n  )+\n  scale_y_tight()+\n  theme_no_y()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=480}\n:::\n:::\n\n\n\n\n# What about a prior?\n\nIn a logistic regression I think I would usually like a prior over $\\sigma$ for random effects to have its expected value right about here, with about as close as we can get to a uniform prior in probability space. Then, the data can pull it towards being more bifurcated, or more focused, depending.\n\nI'm not sure how to *solve* that, but I *can* do a grid search!\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(\n  prior_sigma = seq(1,1.5,length = 100),\n  half_student = dist_student_t(3,0,prior_sigma) |> \n    dist_truncated(lower = 0),\n  expected = mean(half_student)\n)  |> \n  slice(\n    which.min(abs(expected - flattest_sigma))\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 3\n  prior_sigma        half_student expected\n        <dbl>              <dist>    <dbl>\n1        1.28 t(3, 0, 1.3)[0,Inf]     1.41\n```\n\n\n:::\n:::\n\n\n\n\nLet's call it 1.28.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nranef_sigma_prior <- dist_student_t(3, 0, 1.28) |> \n  dist_truncated(lower = 0)\n\nset.seed(2024)\nranef_sigmas <- generate(ranef_sigma_prior, 9)[[1]]\n\n\ntibble(\n  sigma = ranef_sigmas,\n  rounded_sigma = round(sigma, digits = 2),\n  dist = dist_normal(0, sigma),\n  p_dist = dist_transformed(\n    dist, plogis, qlogis\n  )\n) |> \n  ggplot(\n    aes(\n      xdist = p_dist\n    )\n  )+\n  stat_slab(\n    aes(\n      fill = sigma\n    ),\n    normalize = \"panels\",\n    color = \"black\",\n    linewidth = 0.5\n  )+ \n  scale_y_tight()+\n  scale_fill_scico(\n    palette = \"devon\",\n    guide = \"none\"\n  )+\n  scale_x_continuous(\n    breaks = c(0,1)\n  )+\n  facet_wrap(~rounded_sigma)+\n  theme_no_y()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\nLooks good to me!\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}