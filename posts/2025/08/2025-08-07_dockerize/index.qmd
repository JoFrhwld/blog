---
title: Time to Dockerize
date: '2025-08-07'
draft: true
---

Maybe I'm late to this game, but I'm finally getting around to Dockerizing my code for research. I *have* messed around with Docker and [devcontainer images for teaching (specifically for working in github codespaces)](/posts/2024/09/2024-09-06_rserver-codespaces/). And just like I used those images to deliver "mini computers" to my students, I'm using them here to deliver "mini computers" to the compute cluster.

## The conundrum

For this example, I really want to use [DeepFilterNet](https://github.com/Rikorose/DeepFilterNet) to clean up some noisy data, and I don't have the time or GPUs to do it quickly on my own computer. My university's compute cluster has the time (and GPUs), but I don't want to have to email back and forth or open support tickets to make sure I have access to the right python versions. But the cluster does let me run Docker images (via Singularity), so I've just had to figure out to make that work.

## My process

1.  Locally, I create a Docker project, and set up my python environment with [`uv`](https://docs.astral.sh/uv/).
2.  I develop my workflow in a `main.py` python script.
3.  I publish the docker image to the github registry using a github action.
4.  On the cluster, I pull the docker image.
5.  Finally, I submit the job running the image.

You can have a look at the